import pandas as pd
import random
import time
import difflib
import os
import sys
from pathlib import Path
from pyvi import ViTokenizer
from bm25_scorer import calculate_bm25

# Add paths
sys.path.insert(0, str(Path(__file__).parent.parent / "n_gram"))
from gen_mul_layer import BidirectionalBeamGenerator

import matplotlib.pyplot as plt
import seaborn as sns

# C√†i ƒë·∫∑t tqdm ƒë·ªÉ theo d√µi ti·∫øn ƒë·ªô (v√¨ ch·∫°y full data s·∫Ω l√¢u)
try:
    from tqdm import tqdm
except ImportError:
    import subprocess
    import sys
    subprocess.check_call([sys.executable, "-m", "pip", "install", "tqdm"])
    from tqdm import tqdm

# ==============================================================================
# 1. H√ÄM ENSEMBLE GENERATION (N-gram + BM25)
# ==============================================================================
class EnsembleGenerator:
    """Wrapper cho Ensemble generation"""
    
    def __init__(self, model_file, data_file, n_gram_order=5, num_candidates=5):
        self.generator = BidirectionalBeamGenerator(model_file, data_file, n_gram_order=n_gram_order)
        self.num_candidates = num_candidates
    
    def generate_best_cases(self, input_text, num_results=1):
        """
        Generate candidates v√† rank theo BM25
        
        Args:
            input_text (str): Text input
            num_results (int): S·ªë k·∫øt qu·∫£ tr·∫£ v·ªÅ
        
        Returns:
            list: List of (score, text) tuples
        """
        try:
            # B∆∞·ªõc 1: Generate candidates t·ª´ N-gram
            ngram_results = self.generator.generate_best_cases(input_text, num_results=self.num_candidates)
            
            if not ngram_results:
                return []
            
            # B∆∞·ªõc 2: Extract candidates
            candidates = [text for _, text in ngram_results]
            
            # B∆∞·ªõc 3: Score v·ªõi BM25
            scored_results = []
            for candidate in candidates:
                bm25_score = calculate_bm25(input_text, candidate)
                scored_results.append((bm25_score, candidate))
            
            # B∆∞·ªõc 4: Sort by BM25 score (descending)
            scored_results.sort(key=lambda x: x[0], reverse=True)
            
            # Tr·∫£ v·ªÅ top num_results
            return scored_results[:num_results]
        
        except Exception as e:
            print(f"‚ö†Ô∏è Error in ensemble generation: {e}")
            return []

# ==============================================================================
# 2. H√ÄM T·∫†O D·ªÆ LI·ªÜU TEST TO√ÄN DI·ªÜN (FULL STRESS TEST)
# ==============================================================================
def create_full_stress_test(original_file, max_input_ratio=0.7):
    """
    T·∫°o ma tr·∫≠n test ph·ªß k√≠n to√†n b·ªô dataset.
    Kh√¥ng l·∫•y m·∫´u ng·∫´u nhi√™n m√† v√©t c·∫°n m·ªçi tr∆∞·ªùng h·ª£p.
    """
    print(f"üõ† ƒêang x√¢y d·ª±ng ma tr·∫≠n test to√†n di·ªán t·ª´ {original_file}...")
    test_data = []

    # T·∫°o file m·∫´u n·∫øu ch∆∞a c√≥
    if not os.path.exists(original_file):
        sample_text = """
        C√¥ng cha nh∆∞ n√∫i Th√°i S∆°n
        Nghƒ©a m·∫π nh∆∞ n∆∞·ªõc trong ngu·ªìn ch·∫£y ra.
        Anh em nh∆∞ th·ªÉ tay ch√¢n
        R√°ch l√†nh ƒë√πm b·ªçc d·ªü hay ƒë·ª° ƒë·∫ßn.
        """
        with open(original_file, "w", encoding="utf-8") as f:
            f.write(sample_text.strip())

    with open(original_file, "r", encoding="utf-8") as f:
        lines = [line.strip() for line in f if line.strip()]

    # Duy·ªát qua t·ª´ng d√≤ng v·ªõi thanh ti·∫øn tr√¨nh
    for line in tqdm(lines, desc="Processing Data"):
        tokenized_line = ViTokenizer.tokenize(line).lower()
        words = tokenized_line.split()
        n = len(words)

        # B·ªè qua c√¢u qu√° ng·∫Øn
        if n < 3: continue

        ground_truth = " ".join(words)
        max_test_len = max(1, int(n * max_input_ratio))

        # -------------------------------------------------
        # 1. CASE START (ƒê·∫ßu c√¢u -> Test Gen Xu√¥i)
        # -------------------------------------------------
        for k in range(1, max_test_len + 1):
            test_data.append({
                "Lo·∫°i": "Start (ƒê·∫ßu)",
                "Input Len": k,
                "Input": " ".join(words[:k]),
                "Ground_Truth": ground_truth
            })

        # -------------------------------------------------
        # 2. CASE END (Cu·ªëi c√¢u -> Test Gen Ng∆∞·ª£c)
        # -------------------------------------------------
        for k in range(1, max_test_len + 1):
            test_data.append({
                "Lo·∫°i": "End (Cu·ªëi)",
                "Input Len": k,
                "Input": " ".join(words[-k:]),
                "Ground_Truth": ground_truth
            })

        # -------------------------------------------------
        # 3. CASE MID (Gi·ªØa c√¢u -> Test Gen 2 Chi·ªÅu)
        # -------------------------------------------------
        if n >= 5:
            # Qu√©t ƒë·ªô d√†i input t·ª´ 1 ƒë·∫øn max
            for k in range(1, max_test_len + 1):
                # Tr∆∞·ª£t c·ª≠a s·ªï
                for start_idx in range(1, n - k):
                    test_data.append({
                        "Lo·∫°i": "Mid (Gi·ªØa)",
                        "Input Len": k,
                        "Input": " ".join(words[start_idx : start_idx + k]),
                        "Ground_Truth": ground_truth
                    })

    df = pd.DataFrame(test_data)
    print(f"‚úÖ ƒê√£ t·∫°o {len(df)} m·∫´u test cases t·ª´ {len(lines)} c√¢u g·ªëc.")
    return df

# ==============================================================================
# 3. H√ÄM ƒê√ÅNH GI√Å CHI TI·∫æT
# ==============================================================================
def evaluate_full_dataset(generator, test_df):
    print(f"\nüöÄ B·∫ÆT ƒê·∫¶U ƒê√ÅNH GI√Å TR√äN {len(test_df)} M·∫™U...")

    results = []
    correct_count = 0
    total_similarity = 0
    start_time = time.time()

    # Ch·∫°y v√≤ng l·∫∑p ƒë√°nh gi√°
    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc="Evaluating"):
        inp = row['Input']
        truth = row['Ground_Truth']

        try:
            # --- G·ªåI MODEL ENSEMBLE (N-gram + BM25) ---
            gen_output = generator.generate_best_cases(inp, num_results=1)

            if not gen_output:
                pred_clean = ""
                score = -999.0
            else:
                # Unpack k·∫øt qu·∫£: (bm25_score, text)
                score, formatted_text = gen_output[0]

                # --- CHU·∫®N H√ìA K·∫æT QU·∫¢ ƒê·ªÇ SO S√ÅNH ---
                # Model tr·∫£ v·ªÅ d·∫°ng th∆° ƒë·∫πp -> C·∫ßn ƒë∆∞a v·ªÅ d·∫°ng tokenized th∆∞·ªùng
                pred_clean = formatted_text.replace("\n", " ").lower()
                pred_clean = pred_clean.replace(".", "").replace(",", "").strip()
                # Quan tr·ªçng: Ph·∫£i tokenize l·∫°i th√¨ m·ªõi kh·ªõp v·ªõi Ground Truth (vd: th√°i_s∆°n)
                pred_clean = ViTokenizer.tokenize(pred_clean)

        except Exception as e:
            pred_clean = f"Error: {e}"
            score = -999.0

        # Chu·∫©n h√≥a Ground Truth
        truth_clean = truth.replace(".", "").strip()

        # --- CH·∫§M ƒêI·ªÇM ---
        # 1. Exact Match
        is_exact = 1 if pred_clean == truth_clean else 0
        correct_count += is_exact

        # 2. Similarity
        sim = difflib.SequenceMatcher(None, pred_clean, truth_clean).ratio()
        total_similarity += sim

        results.append({
            "Lo·∫°i": row['Lo·∫°i'],
            "Input Len": row['Input Len'],
            "Input": inp,
            "K·∫øt qu·∫£ Gen": pred_clean,
            "ƒê√°p √°n G·ªëc": truth_clean,
            "ƒêi·ªÉm Model": score,
            "ƒê√∫ng": is_exact,
            "ƒê·ªô gi·ªëng": sim
        })

    total_time = time.time() - start_time

    # --- T·∫†O B√ÅO C√ÅO ---
    res_df = pd.DataFrame(results)
    if len(test_df) > 0:
        acc = correct_count / len(test_df) * 100
        avg_sim = total_similarity / len(test_df) * 100
    else:
        acc = 0; avg_sim = 0

    print("\n" + "="*60)
    print(f"üìä B√ÅO C√ÅO HI·ªÜU NƒÇNG TO√ÄN DI·ªÜN (ENSEMBLE)")
    print("="*60)
    print(f"‚è±  Th·ªùi gian: {total_time:.2f}s ({total_time/len(test_df)*1000:.1f} ms/c√¢u)")
    print(f"üéØ ƒê·ªô ch√≠nh x√°c tuy·ªát ƒë·ªëi (Exact Match): {acc:.2f}%")
    print(f"‚âà  ƒê·ªô t∆∞∆°ng ƒë·ªìng trung b√¨nh (Similarity):  {avg_sim:.2f}%")

    # --- PH√ÇN T√çCH 1: THEO V·ªä TR√ç ---
    print("-" * 60)
    print("1. PH√ÇN T√çCH THEO V·ªä TR√ç (Start/Mid/End):")
    # Xem model gi·ªèi chi·ªÅu n√†o h∆°n
    group_type = res_df.groupby("Lo·∫°i")[["ƒê√∫ng", "ƒê·ªô gi·ªëng"]].mean() * 100
    print(group_type.round(2))

    # --- PH√ÇN T√çCH 2: THEO ƒê·ªò D√ÄI INPUT ---
    print("-" * 60)
    print("2. PH√ÇN T√çCH THEO ƒê·ªò D√ÄI INPUT (10 ƒë·ªô d√†i ƒë·∫ßu):")
    # Input c√†ng ng·∫Øn c√†ng kh√≥ ƒëo√°n
    group_len = res_df.groupby("Input Len")[["ƒê√∫ng", "ƒê·ªô gi·ªëng"]].mean().head(10) * 100
    print(group_len.round(2))
    print("="*60)

    return res_df

# ==============================================================================
# 4. H√ÄM V·∫º ƒê·ªí TH·ªä
# ==============================================================================
def plot_evaluation_results(res_df, output_dir):
    """
    V·∫Ω 4 ƒë·ªì th·ªã ph√¢n t√≠ch chi ti·∫øt k·∫øt qu·∫£ ƒë√°nh gi√°
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)
    
    # C·∫•u h√¨nh seaborn
    sns.set_style("whitegrid")
    plt.rcParams['figure.figsize'] = (14, 10)
    plt.rcParams['font.size'] = 10
    
    # --- ƒê·ªí TH·ªä 1: Hi·ªáu nƒÉng theo v·ªã tr√≠ (Start/Mid/End) ---
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # Plot 1: Bar chart - Accuracy by Type
    type_stats = res_df.groupby("Lo·∫°i")[["ƒê√∫ng", "ƒê·ªô gi·ªëng"]].mean() * 100
    type_stats.plot(kind='bar', ax=axes[0, 0], color=['#2ecc71', '#3498db'])
    axes[0, 0].set_title('Hi·ªáu nƒÉng theo v·ªã tr√≠ (Start/Mid/End) - ENSEMBLE', fontsize=12, fontweight='bold')
    axes[0, 0].set_ylabel('Ph·∫ßn trƒÉm (%)')
    axes[0, 0].set_xlabel('V·ªã tr√≠')
    axes[0, 0].legend(['Ch√≠nh x√°c', 'ƒê·ªô gi·ªëng'])
    axes[0, 0].tick_params(axis='x', rotation=45)
    
    # Plot 2: Line chart - Performance by Input Length
    len_stats = res_df.groupby("Input Len")[["ƒê√∫ng", "ƒê·ªô gi·ªëng"]].mean() * 100
    axes[0, 1].plot(len_stats.index, len_stats["ƒê√∫ng"], marker='o', label='Ch√≠nh x√°c', color='#2ecc71', linewidth=2)
    axes[0, 1].plot(len_stats.index, len_stats["ƒê·ªô gi·ªëng"], marker='s', label='ƒê·ªô gi·ªëng', color='#3498db', linewidth=2)
    axes[0, 1].set_title('Hi·ªáu nƒÉng theo ƒë·ªô d√†i input - ENSEMBLE', fontsize=12, fontweight='bold')
    axes[0, 1].set_xlabel('ƒê·ªô d√†i Input (t·ª´)')
    axes[0, 1].set_ylabel('Ph·∫ßn trƒÉm (%)')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # Plot 3: Pie chart - Distribution of Correct/Wrong
    correct_dist = res_df["ƒê√∫ng"].value_counts()
    labels = ['Sai', 'ƒê√∫ng'] if len(correct_dist) > 1 else ['ƒê√∫ng']
    colors = ['#e74c3c', '#2ecc71']
    axes[1, 0].pie(correct_dist.values, labels=[f'{l}\n{v} ({v/len(res_df)*100:.1f}%)' for l, v in zip(labels, correct_dist.values)], 
                   autopct='', colors=colors[:len(correct_dist)], startangle=90)
    axes[1, 0].set_title('Ph√¢n ph·ªëi ƒê√∫ng/Sai - ENSEMBLE', fontsize=12, fontweight='bold')
    
    # Plot 4: Scatter - Input Length vs Similarity
    scatter = axes[1, 1].scatter(res_df["Input Len"], res_df["ƒê·ªô gi·ªëng"] * 100, 
                                 c=res_df["ƒê√∫ng"], cmap='RdYlGn', s=30, alpha=0.6, edgecolors='black', linewidth=0.5)
    axes[1, 1].set_title('Input Length vs ƒê·ªô Gi·ªëng - ENSEMBLE', fontsize=12, fontweight='bold')
    axes[1, 1].set_xlabel('ƒê·ªô d√†i Input (t·ª´)')
    axes[1, 1].set_ylabel('ƒê·ªô gi·ªëng (%)')
    cbar = plt.colorbar(scatter, ax=axes[1, 1])
    cbar.set_label('ƒê√∫ng/Sai')
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # L∆∞u file
    output_file = os.path.join(output_dir, 'evaluation_ensemble_report.png')
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"[SAVED] ƒê·ªì th·ªã l∆∞u t·∫°i: {output_file}")
    plt.close()
    
    # --- ƒê·ªí TH·ªä B·ªî SUNG: Chi ti·∫øt theo t·ª´ng type ---
    fig, axes = plt.subplots(1, 3, figsize=(15, 4))
    
    for idx, type_name in enumerate(res_df["Lo·∫°i"].unique()):
        type_data = res_df[res_df["Lo·∫°i"] == type_name]
        len_stats_type = type_data.groupby("Input Len")[["ƒê·ªô gi·ªëng"]].mean() * 100
        
        axes[idx].plot(len_stats_type.index, len_stats_type["ƒê·ªô gi·ªëng"], 
                      marker='o', linewidth=2, markersize=6, color='#3498db')
        axes[idx].set_title(f'{type_name}', fontsize=11, fontweight='bold')
        axes[idx].set_xlabel('ƒê·ªô d√†i Input (t·ª´)')
        axes[idx].set_ylabel('ƒê·ªô gi·ªëng (%)')
        axes[idx].grid(True, alpha=0.3)
        axes[idx].set_ylim(0, 105)
    
    plt.tight_layout()
    output_file = os.path.join(output_dir, 'evaluation_ensemble_by_type.png')
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"[SAVED] ƒê·ªì th·ªã chi ti·∫øt l∆∞u t·∫°i: {output_file}")
    plt.close()
    
    print(f"‚úÖ T·∫•t c·∫£ ƒë·ªì th·ªã ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {output_dir}")
    return res_df

# ==============================================================================
# 5. CH·∫†Y TH·ª∞C T·∫æ
# ==============================================================================
if __name__ == "__main__":
    # C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n
    project_root = Path(__file__).parent.parent.parent
    data_dir = project_root / "data"
    ensemble_dir = Path(__file__).parent
    ngram_checkpoint_dir = project_root / "models" / "n_gram" / "checkpoint"
    eval_dir = project_root / "evaluation" / "ensemble"
    
    model_file = str(ngram_checkpoint_dir / 'model.bin')
    data_file = str(data_dir / 'train_data_seg.txt')
    raw_dataset = str(data_dir / "dataset.txt")

    try:
        # Ki·ªÉm tra file
        if not os.path.exists(model_file):
            print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y model.bin t·∫°i {model_file}")
            exit(1)
        
        if not os.path.exists(data_file):
            print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y train_data_seg.txt t·∫°i {data_file}")
            exit(1)

        print("‚ö†Ô∏è ƒêang kh·ªüi t·∫°o Ensemble Generator...")
        ensemble_gen = EnsembleGenerator(model_file, data_file, n_gram_order=5, num_candidates=5)

        # 1. T·∫°o dataset test to√†n di·ªán
        full_test_df = create_full_stress_test(raw_dataset, max_input_ratio=0.7)
        
        # L∆∞u file test data
        test_data_file = data_dir / 'dataset_ensemble_test.csv'
        full_test_df.to_csv(test_data_file, index=False, encoding='utf-8')
        print(f"‚úÖ Test data ƒë√£ l∆∞u t·∫°i: {test_data_file}")

        # 2. Ch·∫°y ƒë√°nh gi√°
        df_final = evaluate_full_dataset(ensemble_gen, full_test_df)

        # 3. V·∫Ω ƒë·ªì th·ªã v√† l∆∞u
        plot_evaluation_results(df_final, str(eval_dir))

        # 4. Xu·∫•t c√°c c√¢u sai ƒë·ªÉ debug
        print("\nüîç TOP 5 C√ÇU SAI ƒêI·ªÇN H√åNH:")
        wrong_cases = df_final[df_final["ƒê√∫ng"] == 0].head(5)
        if not wrong_cases.empty:
            pd.set_option('display.max_colwidth', None)
            print(wrong_cases[['Lo·∫°i', 'Input', 'K·∫øt qu·∫£ Gen', 'ƒê√°p √°n G·ªëc', 'ƒê·ªô gi·ªëng']])
        else:
            print("‚úÖ Xu·∫•t s·∫Øc! Model ƒë√∫ng 100%.")

    except Exception as e:
        print(f"L·ªói: {e}")
        import traceback
        traceback.print_exc()
