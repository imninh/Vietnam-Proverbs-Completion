# ğŸ¯ Ca Dao & Tá»¥c Ngá»¯ Autocomplete

> Há»‡ thá»‘ng tá»± Ä‘á»™ng hoÃ n thiá»‡n cÃ¢u ca dao vÃ  tá»¥c ngá»¯ Viá»‡t Nam sá»­ dá»¥ng Machine Learning

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Development-yellow.svg)]()

---

## ğŸ“– Table of Contents

- [Giá»›i thiá»‡u](#-giá»›i-thiá»‡u)
- [Demo](#-demo)
- [Kiáº¿n trÃºc há»‡ thá»‘ng](#-kiáº¿n-trÃºc-há»‡-thá»‘ng)
- [Models](#-models)
- [CÃ i Ä‘áº·t](#-cÃ i-Ä‘áº·t)
- [Sá»­ dá»¥ng](#-sá»­-dá»¥ng)
- [Káº¿t quáº£](#-káº¿t-quáº£)
- [API Documentation](#-api-documentation)
- [Project Structure](#-project-structure)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸŒŸ Giá»›i thiá»‡u

### Váº¥n Ä‘á»

Ca dao vÃ  tá»¥c ngá»¯ Viá»‡t Nam lÃ  di sáº£n vÄƒn hÃ³a quÃ½ bÃ¡u, nhÆ°ng nhiá»u ngÆ°á»i tráº» khÃ´ng nhá»› Ä‘á»§ hoáº·c nhá»› sai. Project nÃ y giÃºp:

- âœ… Gá»£i Ã½ hoÃ n thiá»‡n cÃ¢u ca dao/tá»¥c ngá»¯ khi nháº­p má»™t pháº§n
- âœ… GiÃ¡o dá»¥c vÃ  báº£o tá»“n vÄƒn hÃ³a truyá»n thá»‘ng
- âœ… Há»— trá»£ há»c sinh, giÃ¡o viÃªn, ngÆ°á»i yÃªu vÄƒn hÃ³a

### Giáº£i phÃ¡p

Há»‡ thá»‘ng sá»­ dá»¥ng **ensemble cá»§a nhiá»u ML models** Ä‘á»ƒ Ä‘Æ°a ra gá»£i Ã½ thÃ´ng minh:

```
User input: "Äƒn quáº£"
â†“
System output:
  1. ğŸŸ¢ [95%] Äƒn quáº£ nhá»› káº» trá»“ng cÃ¢y
  2. ğŸŸ¡ [70%] gieo nhÃ¢n nÃ o gáº·t quáº£ náº¥y
  3. ğŸŸ¡ [65%] Äƒn chÃ¡o Ä‘Ã¡ bÃ¡t
```

---

## ğŸ¬ Demo

### Interactive Terminal

```bash
python backend/models/interactive_autocomplete.py
```

![Demo GIF](docs/demo.gif)

### Web Interface (Coming Soon)

```bash
cd frontend
npm start
```

---

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   USER INPUT                         â”‚
â”‚              "Äƒn quáº£" / "cÃ³ cÃ´ng"                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            SMART FALLBACK SYSTEM                     â”‚
â”‚  (Coordinate multiple strategies & models)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚             â”‚             â”‚
        â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Strategy 1  â”‚ â”‚  Strategy 2  â”‚ â”‚  Strategy 3  â”‚
â”‚ Exact Prefix â”‚ â”‚ Fuzzy Match  â”‚ â”‚   Semantic   â”‚
â”‚  (95% conf)  â”‚ â”‚  (85% conf)  â”‚ â”‚  (70% conf)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              WEIGHTED VOTING                         â”‚
â”‚     (Combine scores from all strategies)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TOP-K SUGGESTIONS                       â”‚
â”‚   1. [95%] Äƒn quáº£ nhá»› káº» trá»“ng cÃ¢y                  â”‚
â”‚   2. [70%] gieo nhÃ¢n nÃ o gáº·t quáº£ náº¥y                â”‚
â”‚   3. [65%] Äƒn chÃ¡o Ä‘Ã¡ bÃ¡t                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### System Workflow

1. **Input Processing**: Normalize vÃ  tokenize user input
2. **Multi-Strategy Search**: 
   - Exact prefix matching (fastest, most accurate)
   - Fuzzy matching (handle typos)
   - Semantic similarity (understand meaning)
   - Keyword retrieval (fallback)
   - Popular sentences (last resort)
3. **Weighted Voting**: Combine scores with confidence calibration
4. **Re-ranking**: Sort by confidence and strategy priority
5. **Output**: Return top-K suggestions with confidence scores

---

## ğŸ¤– Models

### 1. **Retrieval Model** (TF-IDF + Cosine Similarity)

**Accuracy**: 55% | **Speed**: âš¡âš¡âš¡ Fast

```python
from backend.models.retrieval import RetrievalModel

model = RetrievalModel()
model.train(train_data)

# Usage
candidates = model.predict_multiple("Äƒn quáº£", top_k=3)
# â†’ [{'text': '...', 'confidence': 0.85, 'similarity': 0.75}]
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Nhanh (pre-computed TF-IDF vectors)
- âœ… LuÃ´n tráº£ vá» cÃ¢u hoÃ n chá»‰nh
- âœ… Tá»‘t cho keyword matching

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ KhÃ´ng hiá»ƒu semantic (Ã½ nghÄ©a)
- âŒ Phá»¥ thuá»™c vÃ o exact keywords

---

### 2. **Semantic Model** (Sentence Embeddings)

**Accuracy**: 50-55% | **Speed**: âš¡âš¡ Medium

```python
from backend.models.semantic_fill_blank import SemanticFillBlankModel

model = SemanticFillBlankModel()
model.train(train_data)

# Usage
candidates = model.predict_multiple("Äƒn quáº£", top_k=3)
# â†’ TÃ¬m cÃ¢u cÃ³ Ã½ nghÄ©a tÆ°Æ¡ng tá»±
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Hiá»ƒu semantic similarity
- âœ… CÃ³ thá»ƒ match cÃ¢u khÃ¡c tá»« khÃ³a nhÆ°ng cÃ¹ng Ã½ nghÄ©a
- âœ… Tá»‘t cho inputs mÆ¡ há»“

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Cháº­m hÆ¡n Retrieval
- âŒ Cáº§n model pre-trained (vietnamese-sbert)

---

### 3. **N-gram Model** (Statistical Language Model)

**Accuracy**: 15% | **Speed**: âš¡âš¡âš¡ Fast

```python
from backend.models.ngram import NgramModel

model = NgramModel(n=3)  # Trigram
model.train(train_data)

# Usage
prediction = model.predict("Äƒn quáº£")
# â†’ Generate tá»«ng tá»« tiáº¿p theo
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Simple, interpretable
- âœ… Nhanh

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Accuracy ráº¥t tháº¥p (15%)
- âŒ KhÃ´ng phÃ¹ há»£p vá»›i task nÃ y
- âš ï¸ **KHÃ”NG khuyáº¿n nghá»‹ dÃ¹ng**

---

### 4. **Transformer Mini** (Attention-based)

**Accuracy**: 40-50% | **Speed**: âš¡ Slow

```python
from backend.models.transformer_mini import TransformerCaDao

model = TransformerCaDao()
model.train(train_data, epochs=20)

# Usage
prediction = model.predict("Äƒn quáº£")
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… State-of-the-art architecture
- âœ… CÃ³ thá»ƒ há»c patterns phá»©c táº¡p

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Cáº§n nhiá»u data Ä‘á»ƒ train tá»‘t
- âŒ Slow inference
- âŒ Overfitting vá»›i dataset nhá» (2,265 samples)

---

### 5. **Improved Ensemble** (Retrieval + Semantic)

**Accuracy**: 62% â­ | **Speed**: âš¡âš¡ Medium

```python
from backend.models.ensemble import ImprovedEnsembleModel
from backend.models.retrieval import RetrievalModel
from backend.models.semantic_fill_blank import SemanticFillBlankModel

# Load models
retrieval = RetrievalModel()
retrieval.load("trained_models/retrieval_model.pkl")

semantic = SemanticFillBlankModel()
semantic.load("trained_models/semantic_model.pkl")

# Create ensemble
ensemble = ImprovedEnsembleModel(retrieval, semantic)

# Usage
candidates = ensemble.predict_multiple("Äƒn quáº£", top_k=5)
```

**Strategy:**
- Weighted voting: Retrieval (60%) + Semantic (40%)
- Diversity bonus cho candidates xuáº¥t hiá»‡n á»Ÿ cáº£ 2 models
- Adaptive confidence calibration

**Æ¯u Ä‘iá»ƒm:**
- âœ… **Accuracy cao nháº¥t** (62%)
- âœ… Káº¿t há»£p keyword + semantic
- âœ… Robust vá»›i nhiá»u loáº¡i inputs

---

## ğŸš€ CÃ i Ä‘áº·t

### Prerequisites

- Python 3.8+
- pip
- (Optional) GPU cho training Transformer

### Installation Steps

```bash
# 1. Clone repository
git clone https://github.com/yourusername/cadao-tucngu-nlp.git
cd cadao-tucngu-nlp

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# hoáº·c
venv\Scripts\activate     # Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Download data (if not included)
python backend/data/download_data.py

# 5. Preprocess data
python backend/data/preprocess.py
```

### Requirements.txt

```txt
# Core
numpy>=1.21.0
pandas>=1.3.0
scikit-learn>=1.0.0

# NLP
sentence-transformers>=2.2.0
torch>=1.10.0

# Utils
tqdm>=4.62.0
python-dotenv>=0.19.0

# Web (optional)
fastapi>=0.70.0
uvicorn>=0.15.0

# Testing
pytest>=7.0.0
```

---

## ğŸ“š Sá»­ dá»¥ng

### 1. Training Models

#### Train Retrieval Model

```bash
cd backend/models
python retrieval.py
```

Output:
```
ğŸš€ RETRIEVAL MODEL TRAINING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ“ Train: 2265 samples
âœ“ Test:  486 samples
âœ“ Database: 1492 unique sentences
âœ“ Accuracy: 55.0%
âœ“ Model saved: trained_models/retrieval_model.pkl
```

#### Train Semantic Model

```bash
python semantic_fill_blank.py
```

#### Train Ensemble

```bash
python ensemble.py
```

---

### 2. Interactive Terminal

```bash
python interactive_autocomplete.py
```

**Example Session:**

```
ğŸ¯ INTERACTIVE AUTOCOMPLETE - Ca Dao & Tá»¥c Ngá»¯
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

>>> Nháº­p: Äƒn quáº£

   ğŸ“‹ Suggestions:
   1. ğŸŸ¢ [95% HIGH] ğŸ¯ Äƒn quáº£ nhá»› káº» trá»“ng cÃ¢y
   2. ğŸŸ¡ [70% MED ] ğŸ”¤ gieo nhÃ¢n nÃ o gáº·t quáº£ náº¥y
   3. ğŸ”´ [45% LOW ] â­ Äƒn chÃ¡o Ä‘Ã¡ bÃ¡t

>>> Nháº­p: cÃ³ cÃ´ng

   ğŸ“‹ Suggestions:
   1. ğŸŸ¢ [95% HIGH] ğŸ¯ cÃ³ cÃ´ng mÃ i sáº¯t cÃ³ ngÃ y nÃªn kim
   2. ğŸŸ¡ [70% MED ] ğŸ”¤ cÃ´ng cha nhÆ° nÃºi thÃ¡i sÆ¡n

>>> Nháº­p: q
ğŸ‘‹ Goodbye!
```

---

### 3. Python API

```python
from backend.models.retrieval import RetrievalModel
from backend.models.semantic_fill_blank import SemanticFillBlankModel
from backend.models.ensemble import ImprovedEnsembleModel

# Load models
retrieval = RetrievalModel()
retrieval.load("backend/trained_models/retrieval_model.pkl")

semantic = SemanticFillBlankModel()
semantic.load("backend/trained_models/semantic_model.pkl")

# Create ensemble
ensemble = ImprovedEnsembleModel(retrieval, semantic)

# Get suggestions
user_input = "Äƒn quáº£"
suggestions = ensemble.predict_multiple(user_input, top_k=5)

for i, sugg in enumerate(suggestions, 1):
    print(f"{i}. [{sugg['confidence']:.0%}] {sugg['text']}")
```

---

### 4. REST API (FastAPI)

```bash
cd backend
uvicorn api.main:app --reload
```

**Endpoint:**

```bash
POST /api/autocomplete
Content-Type: application/json

{
  "input": "Äƒn quáº£",
  "top_k": 5,
  "min_confidence": 0.5
}
```

**Response:**

```json
{
  "suggestions": [
    {
      "text": "Äƒn quáº£ nhá»› káº» trá»“ng cÃ¢y",
      "confidence": 0.95,
      "strategy": "exact_prefix"
    },
    {
      "text": "gieo nhÃ¢n nÃ o gáº·t quáº£ náº¥y",
      "confidence": 0.70,
      "strategy": "word_match"
    }
  ],
  "query_time_ms": 15.3
}
```

---

## ğŸ“Š Káº¿t quáº£

### Model Comparison

| Model | Exact Acc | Top-3 Acc | Top-5 Acc | Speed | Production Ready |
|-------|-----------|-----------|-----------|-------|------------------|
| **N-gram** | 15.0% | 30.0% | - | âš¡âš¡âš¡ | âŒ |
| **Retrieval** | 55.0% | 70.0% | - | âš¡âš¡âš¡ | âœ… |
| **Semantic** | 50-55% | 65-70% | - | âš¡âš¡ | âœ… |
| **Transformer** | 40-50% | 60-65% | - | âš¡ | âŒ |
| **Ensemble** | **62.0%** | **69.5%** | **71.0%** | âš¡âš¡ | âœ… â­ |

### Strategy Performance

| Strategy | Accuracy | Use Cases | Confidence |
|----------|----------|-----------|------------|
| **Exact Prefix** | 90-95% | Input dÃ i, rÃµ rÃ ng | 95% |
| **Fuzzy Prefix** | 80-85% | Input cÃ³ typo | 85% |
| **Semantic** | 60-70% | Input vá» Ã½ nghÄ©a | 70% |
| **Retrieval** | 55-60% | Keyword matching | 60% |
| **Popular** | 30-40% | Fallback | 40% |

### Real-world Performance

**Test Cases:**

| Input | Expected | Model Output | Correct? |
|-------|----------|--------------|----------|
| "Äƒn quáº£" | Äƒn quáº£ nhá»› káº» trá»“ng cÃ¢y | âœ… Same | âœ… |
| "cÃ³ cÃ´ng" | cÃ³ cÃ´ng mÃ i sáº¯t cÃ³ ngÃ y nÃªn kim | âœ… Same | âœ… |
| "gáº§n má»±c" | gáº§n má»±c thÃ¬ Ä‘en gáº§n Ä‘Ã¨n thÃ¬ sÃ¡ng | âœ… Same | âœ… |
| "há»c tháº§y" | há»c tháº§y khÃ´ng tÃ y há»c báº¡n | âŒ nhÆ° tháº§y tÄƒng tháº§y lá»™ | âŒ |

**Success Rate**: 75% (3/4)

---

## ğŸ”Œ API Documentation

### Endpoints

#### `POST /api/autocomplete`

Autocomplete cÃ¢u ca dao/tá»¥c ngá»¯.

**Request:**
```json
{
  "input": "string",           // Required: User input
  "top_k": 5,                  // Optional: Number of suggestions (default: 5)
  "min_confidence": 0.5,       // Optional: Min confidence threshold (default: 0.5)
  "strategy": "auto"           // Optional: "auto" | "exact" | "semantic" | "retrieval"
}
```

**Response:**
```json
{
  "suggestions": [
    {
      "text": "string",
      "confidence": 0.95,
      "strategy": "exact_prefix",
      "rank": 1
    }
  ],
  "query_time_ms": 15.3,
  "total_candidates": 10
}
```

#### `GET /api/stats`

Láº¥y thá»‘ng kÃª há»‡ thá»‘ng.

**Response:**
```json
{
  "total_sentences": 1492,
  "models_loaded": ["retrieval", "semantic"],
  "cache_size": 1500,
  "uptime_seconds": 3600
}
```

---

## ğŸ“ Project Structure

```
cadao-tucngu-nlp/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ raw/                    # Raw data files
â”‚   â”‚   â”‚   â””â”€â”€ cadao_tucngu.txt
â”‚   â”‚   â”œâ”€â”€ processed/              # Processed data
â”‚   â”‚   â”‚   â”œâ”€â”€ train.json
â”‚   â”‚   â”‚   â”œâ”€â”€ val.json
â”‚   â”‚   â”‚   â””â”€â”€ test.json
â”‚   â”‚   â”œâ”€â”€ preprocess.py           # Data preprocessing script
â”‚   â”‚   â””â”€â”€ download_data.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ retrieval.py            # TF-IDF Retrieval model
â”‚   â”‚   â”œâ”€â”€ semantic_fill_blank.py  # Semantic model
â”‚   â”‚   â”œâ”€â”€ ngram.py                # N-gram model
â”‚   â”‚   â”œâ”€â”€ transformer_mini.py     # Transformer model
â”‚   â”‚   â”œâ”€â”€ ensemble.py             # Ensemble model
â”‚   â”‚   â”œâ”€â”€ interactive_autocomplete.py  # Interactive terminal
â”‚   â”‚   â””â”€â”€ smart_fallback_system.py     # Production system
â”‚   â”‚
â”‚   â”œâ”€â”€ trained_models/             # Saved models
â”‚   â”‚   â”œâ”€â”€ retrieval_model.pkl
â”‚   â”‚   â”œâ”€â”€ semantic_model.pkl
â”‚   â”‚   â””â”€â”€ ensemble_config.pkl
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI app
â”‚   â”‚   â”œâ”€â”€ routes.py
â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ metrics.py              # Evaluation metrics
â”‚       â””â”€â”€ helpers.py
â”‚
â”œâ”€â”€ frontend/                       # (Coming soon)
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_retrieval.py
â”‚   â”œâ”€â”€ test_semantic.py
â”‚   â””â”€â”€ test_ensemble.py
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ model_comparison.md
â”‚   â”œâ”€â”€ api_guide.md
â”‚   â””â”€â”€ training_guide.md
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â””â”€â”€ .gitignore
```

---

## ğŸ§ª Testing

### Run All Tests

```bash
pytest tests/ -v
```

### Test Individual Models

```bash
# Test retrieval
python backend/models/retrieval.py

# Test semantic
python backend/models/semantic_fill_blank.py

# Test ensemble
python backend/models/ensemble.py
```

### Evaluation

```python
from backend.models.retrieval import RetrievalModel
import json

# Load test data
with open('backend/data/processed/test.json', 'r') as f:
    test_data = json.load(f)

# Load model
model = RetrievalModel()
model.load('backend/trained_models/retrieval_model.pkl')

# Evaluate
metrics = model.evaluate(test_data)

print(f"Accuracy: {metrics['exact_accuracy']:.1%}")
print(f"Top-3 Accuracy: {metrics['top3_accuracy']:.1%}")
```

---

## ğŸ“ˆ Performance Optimization

### Tips for Better Performance

1. **Cache frequently queried inputs**
   ```python
   from functools import lru_cache
   
   @lru_cache(maxsize=1000)
   def get_suggestions(input_text):
       return model.predict_multiple(input_text)
   ```

2. **Use batch inference**
   ```python
   # Instead of
   for text in texts:
       model.predict(text)
   
   # Use
   model.predict_batch(texts)
   ```

3. **Optimize model weights**
   ```python
   ensemble.optimize_weights(val_data, steps=10)
   ```

4. **Use appropriate top_k**
   - User-facing: `top_k=3-5`
   - Internal processing: `top_k=10-20`

---

## ğŸ› Troubleshooting

### Common Issues

**1. Model file not found**
```
FileNotFoundError: [Errno 2] No such file or directory: 'trained_models/retrieval_model.pkl'
```
**Solution:** Train the model first:
```bash
python backend/models/retrieval.py
```

---

**2. Scikit-learn version warning**
```
InconsistentVersionWarning: Trying to unpickle estimator from version 1.7.2 when using version 1.6.1
```
**Solution:** Update scikit-learn:
```bash
pip install --upgrade scikit-learn
```

---

**3. Low accuracy on custom data**
```
Model accuracy: 30% (expected 55%+)
```
**Solution:** 
- Ensure data format is correct
- Increase training data size
- Check data quality (duplicates, typos)

---

**4. Slow inference**
```
Query time: 500ms (expected <50ms)
```
**Solution:**
- Enable caching
- Use lighter models (Retrieval instead of Semantic)
- Reduce top_k parameter

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. **Fork the repository**
2. **Create a feature branch**
   ```bash
   git checkout -b feature/amazing-feature
   ```
3. **Commit your changes**
   ```bash
   git commit -m "Add amazing feature"
   ```
4. **Push to the branch**
   ```bash
   git push origin feature/amazing-feature
   ```
5. **Open a Pull Request**

### Development Guidelines

- Follow PEP 8 style guide
- Add docstrings to all functions
- Write unit tests for new features
- Update README.md if needed

---

## ğŸ“ License

This pimninh/cadao-tucngu-nlp)

---

## ğŸ—ºï¸ Roadmap

- [x] Basic retrieval model
- [x] Semantic model
- [x] Ensemble system
- [x] Interactive terminal
- [ ] Web interface (React)
- [ ] Mobile app (React Native)
- [ ] User feedback collection
- [ ] Model fine-tuning with user data
- [ ] Multi-language support (English sayings)
- [ ] Voice input support
- [ ] Educational games

---

## ğŸ“š Further Reading

- [Model Comparison Guide](docs/model_comparison.md)
- [API Usage Guide](docs/api_guide.md)
- [Training Custom Models](docs/training_guide.md)
- [Deployment Guide](docs/deployment.md)

---

<div align="center">

**â­ Star this repo if you find it useful! â­**

Made with â¤ï¸ and â˜• by [Group 16]

</div>
